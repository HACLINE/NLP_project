python bin/evaluate.py \
	--model-dir data/models/all \
	--device cpu \
	--dataset data/test-data/google.jsonl \
	--pred-round 1 
====================================================================================================
RESULTS:
==================== Length (#tokens): ====================
src-len: 26.95
tgt-len: 11.01
pred-len: 17.17

==================== Compression ratio: ====================
tgt-cr: 0.45
pred-cr: 0.67

==================== Token F1-Score: ====================
f1-score: 0.654

==================== ROUGE F1-Scores: ====================
rouge1: 0.6451
rouge2: 0.4914
rougeL: 0.6420

==================== ROUGE Recall: ====================
rouge1: 0.8617
rouge2: 0.6803
rougeL: 0.8577

python bin/evaluate.py \
	--model-dir data/models/all \
	--device cpu \
	--dataset data/test-data/duc2004.jsonl \
	--max-chars 75 \
	--pred-round 1
====================================================================================================
RESULTS:
==================== Length (#tokens): ====================
src-len: 32.93
tgt-len: 11.86
pred-len: 11.84

==================== Compression ratio: ====================
tgt-cr: 0.41
pred-cr: 0.40

==================== Token F1-Score: ====================
f1-score: 0.183

==================== ROUGE F1-Scores: ====================
rouge1: 0.2345
rouge2: 0.0740
rougeL: 0.2039

==================== ROUGE Recall: ====================
rouge1: 0.2479
rouge2: 0.0791
rougeL: 0.2158

python bin/evaluate.py \
	--model-dir data/models/all \
	--device cpu \
	--dataset data/test-data/gigaword.jsonl \
	--pretokenized \
	--pred-round 1
====================================================================================================
RESULTS:
==================== Length (#tokens): ====================
src-len: 29.70
tgt-len: 8.79
pred-len: 16.04

==================== Compression ratio: ====================
tgt-cr: 0.40
pred-cr: 0.57

==================== Token F1-Score: ====================
f1-score: 0.241

==================== ROUGE F1-Scores: ====================
rouge1: 0.2877
rouge2: 0.0991
rougeL: 0.2520

==================== ROUGE Recall: ====================
rouge1: 0.4146
rouge2: 0.1471
rougeL: 0.3626

python bin/evaluate.py \
	--model-dir data/models/all \
	--device cpu \
	--dataset data/test-data/broadcast.jsonl \
	--pretokenized \
	--pred-round 1
====================================================================================================
RESULTS:
==================== Length (#tokens): ====================
src-len: 19.82
tgt-len: 14.37
pred-len: 11.96

==================== Compression ratio: ====================
tgt-cr: 0.76
pred-cr: 0.70

==================== Token F1-Score: ====================
f1-score: 0.738

==================== ROUGE F1-Scores: ====================
rouge1: 0.7434
rouge2: 0.5030
rougeL: 0.7394

==================== ROUGE Recall: ====================
rouge1: 0.7365
rouge2: 0.5047
rougeL: 0.7326

python bin/evaluate.py \
	--model-dir data/models/all \
	--device cpu \
	--dataset data/test-data/bnc.jsonl \
	--pretokenized \
	--pred-round 1
====================================================================================================
RESULTS:
==================== Length (#tokens): ====================
src-len: 27.86
tgt-len: 19.29
pred-len: 15.60

==================== Compression ratio: ====================
tgt-cr: 0.72
pred-cr: 0.63

==================== Token F1-Score: ====================
f1-score: 0.702

==================== ROUGE F1-Scores: ====================
rouge1: 0.7115
rouge2: 0.4750
rougeL: 0.7056

==================== ROUGE Recall: ====================
rouge1: 0.7000
rouge2: 0.4726
rougeL: 0.6944

python bin/evaluate.py \
	--model-dir data/models/all \
	--device cpu \
	--dataset data/test-data/google.jsonl \
	--pred-round 5 
